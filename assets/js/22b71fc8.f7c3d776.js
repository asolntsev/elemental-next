"use strict";(self.webpackChunkfrontend=self.webpackChunkfrontend||[]).push([[68494],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>d});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function s(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function l(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?s(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):s(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function o(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},s=Object.keys(e);for(n=0;n<s.length;n++)r=s[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)r=s[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var i=n.createContext({}),u=function(e){var t=n.useContext(i),r=t;return e&&(r="function"==typeof e?e(t):l(l({},t),e)),r},p=function(e){var t=u(e.components);return n.createElement(i.Provider,{value:t},e.children)},c="mdxType",f={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,s=e.originalType,i=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),c=u(r),m=a,d=c["".concat(i,".").concat(m)]||c[m]||f[m]||s;return r?n.createElement(d,l(l({ref:t},p),{},{components:r})):n.createElement(d,l({ref:t},p))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var s=r.length,l=new Array(s);l[0]=m;var o={};for(var i in t)hasOwnProperty.call(t,i)&&(o[i]=t[i]);o.originalType=e,o[c]="string"==typeof e?e:a,l[1]=o;for(var u=2;u<s;u++)l[u]=r[u];return n.createElement.apply(null,l)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},53618:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>i,contentTitle:()=>l,default:()=>f,frontMatter:()=>s,metadata:()=>o,toc:()=>u});var n=r(87462),a=(r(67294),r(3905));const s={hide_table_of_contents:!0,publish_date:new Date("2014-06-24T00:00:00.000Z"),last_update:{date:new Date("2023-04-06T00:00:00.000Z")},level:3,language:"ruby"},l=void 0,o={unversionedId:"retry-failed-tests/ruby",id:"retry-failed-tests/ruby",title:"ruby",description:"A Solution",source:"@site/docs/56-retry-failed-tests/ruby.md",sourceDirName:"56-retry-failed-tests",slug:"/retry-failed-tests/ruby",permalink:"/docs/retry-failed-tests/ruby",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/56-retry-failed-tests/ruby.md",tags:[],version:"current",lastUpdatedBy:"Diego Molina",lastUpdatedAt:1680739200,formattedLastUpdatedAt:"Apr 6, 2023",frontMatter:{hide_table_of_contents:!0,publish_date:"2014-06-24T00:00:00.000Z",last_update:{date:"2023-04-06T00:00:00.000Z"},level:3,language:"ruby"}},i={},u=[{value:"A Solution",id:"a-solution",level:2},{value:"Example",id:"example",level:2},{value:"Expected Behavior",id:"expected-behavior",level:2},{value:"Summary",id:"summary",level:2},{value:"About The Author",id:"about-the-author",level:2}],p={toc:u},c="wrapper";function f(e){let{components:t,...r}=e;return(0,a.kt)(c,(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"a-solution"},"A Solution"),(0,a.kt)("p",null,"Rather than rerun your entire test suite to suss out transient failures -- you can log which tests fail, and retry\njust those a second time."),(0,a.kt)("p",null,"Let's continue with an example."),(0,a.kt)("h2",{id:"example"},"Example"),(0,a.kt)("p",null,"Let's assume we have a bunch of tests written in ",(0,a.kt)("a",{parentName:"p",href:"http://rspec.info/"},"RSpec"),", which would look something like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sh"},"\u2514\u2500\u2500 spec\n    \u251c\u2500\u2500 11_spec.rb\n    \u251c\u2500\u2500 1_spec.rb\n    \u251c\u2500\u2500 2_spec.rb\n    \u251c\u2500\u2500 3_spec.rb\n    \u251c\u2500\u2500 4_spec.rb\n    \u251c\u2500\u2500 5_spec.rb\n    \u251c\u2500\u2500 6_spec.rb\n    \u251c\u2500\u2500 7_spec.rb\n    \u251c\u2500\u2500 8_spec.rb\n    \u251c\u2500\u2500 9_spec.rb\n    \u2514\u2500\u2500 this_spec.rb\n")),(0,a.kt)("p",null,"And let's assume that we will execute these tests in parallel (using ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/grosser/parallel_tests"},"parallel_tests"),")."),(0,a.kt)("p",null,"Some of the tests will pass, and some of them will fail. In order to track which ones fail, we will want to keep a\nlog. The simplest way to do this would be to output a list of failures to a file. That way the list of failures will\npersist after the suite of tests completes, so we can perform a retry action using the list of failures."),(0,a.kt)("p",null,"Thankfully RSpec comes with some of the plumbing to help accomplish this -- through the use of a\n",(0,a.kt)("a",{parentName:"p",href:"https://github.com/dchelimsky/rspec/wiki/Custom-Formatters"},"custom formatter"),"; specifically the ",(0,a.kt)("a",{parentName:"p",href:"http://rubydoc.info/gems/rspec-core/2.6.4/RSpec/Core/Formatters/BaseFormatter"},"base formatter"),"."),(0,a.kt)("p",null,"Let's create one."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ruby"},'# filename: failure_catcher.rb\n\nrequire \'rspec/core/formatters/base_formatter\'\n\nclass FailureCatcher < RSpec::Core::Formatters::BaseFormatter\n\n  # create files called rspec_#.failures with a list of failed examples\n  def dump_failures\n    return if failed_examples.empty?\n    f = File.new("rspec#{ENV[\'TEST_ENV_NUMBER\']}.failures", "w+")\n    failed_examples.each do |example|\n      f.puts retry_command(example)\n    end\n    f.close\n  end\n\n  def retry_command(example)\n    example_name = example.full_description.gsub("\\"", "\\\\\\"")\n    "-e \\"#{example_name}\\""\n  end\n\nend\n')),(0,a.kt)("p",null,"In order to extend the base formatter we first need to require it, and then inherit from it when declaring our\nclass (e.g., ",(0,a.kt)("inlineCode",{parentName:"p"},"< RSpec::Core::Formatters::BaseFormatter"),")."),(0,a.kt)("p",null,"After that we have access to the helper method we want (e.g., ",(0,a.kt)("inlineCode",{parentName:"p"},"dump_failures"),"). In ",(0,a.kt)("inlineCode",{parentName:"p"},"dump_failures")," we can access\ndetailed information about each failed test through the ",(0,a.kt)("inlineCode",{parentName:"p"},"failed_examples")," accessor."),(0,a.kt)("p",null,"After checking to see if there are any failed examples, we create a new uniquely named file (leveraging the\nenvironment variable created by our parallel executor), iterate through all of the failed examples, and store a\nproperly formatted retry execution command with the name of the failed test."),(0,a.kt)("p",null,"To use this formatter we'll need to specify it at run-time, and to leverage a retry action we'll need to wrap our\nrun-time execution. Let's wire all of this up using ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/jimweirich/rake"},"Rake"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ruby"},"# filename: Rakefile\n\ndef gather_failures\n  opts = \"\"\n  files = Dir.glob('*.failures')\n  files.each { |file| opts << File.read(file).gsub(/\\n/, ' ') }\n  all_failures = './all.failures'\n  File.write(all_failures, opts.rstrip)\n  return File.read all_failures\nend\n\ndef cleanup(files = '')\n  system(\"rm #{files}\") unless Dir.glob(\"#{files}\").empty?\nend\n\ndef launch(params = {})\n  if params[:test_options].include? '-e'\n    count = params[:test_options].split(/failed/).count - 1\n    puts \"Retrying #{count} failed tests!\"\n  end\n  system(\"parallel_rspec -n #{params[:processes] || 5} \\\n          --test-options '#{params[:test_options]}' spec\")\nend\n\ndef run(processes = 5)\n  launch(processes: processes,\n    test_options: '--require ./failure_catcher.rb \\\n    --format FailureCatcher')\nend\n\ndef rerun(processes = 5)\n  launch(processes: processes, test_options: gather_failures)\nend\n\ndesc \"parallel test execution with failure retries\"\ntask :run_tests, :number_of_processes do |t, args|\n  run args[:number_of_processes]\n  unless $?.success?\n    rerun args[:number_of_processes]\n    cleanup '*.failures'\n  end\nend\n")),(0,a.kt)("p",null,"There are five methods and one Rake task. The first two methods (",(0,a.kt)("inlineCode",{parentName:"p"},"gather_failures")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"cleanup"),") are for rounding\nup a list of failed tests from the *.failure files and deleting them when we're finished. The next three methods\n(",(0,a.kt)("inlineCode",{parentName:"p"},"launch"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"run"),", and ",(0,a.kt)("inlineCode",{parentName:"p"},"rerun"),") are for executing the test suite and retrying just the failures."),(0,a.kt)("p",null,"The Rake task is where we tie everything together."),(0,a.kt)("p",null,"In it we make the number of concurrent processes configurable through the use of an optional run-time argument.\nWe then call ",(0,a.kt)("inlineCode",{parentName:"p"},"run")," (passing in the argument) which executes the full suite. After the suite completes,\nwe perform a check against the exit code to see if there were any failures. If there were, then we call\n",(0,a.kt)("inlineCode",{parentName:"p"},"rerun")," (along with the argument for number of processes),  and then call ",(0,a.kt)("inlineCode",{parentName:"p"},"cleanup")," to remove the failure files."),(0,a.kt)("h2",{id:"expected-behavior"},"Expected Behavior"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Tests execute in parallel"),(0,a.kt)("li",{parentName:"ul"},"A list of failed tests get stored in output files (one for each process)"),(0,a.kt)("li",{parentName:"ul"},"Failed tests get rerun"),(0,a.kt)("li",{parentName:"ul"},"Output files for failed tests get deleted")),(0,a.kt)("h2",{id:"summary"},"Summary"),(0,a.kt)("p",null,"Hat-tip to ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/dblock/rspec-rerun"},"rspec-rerun")," for the initial implementation, and to ",(0,a.kt)("a",{parentName:"p",href:"http://artsy.github.io/blog/2012/05/15/how-to-organize-over-3000-rspec-specs-and-retry-test-failures/"},"the write-up that led me there"),"."),(0,a.kt)("p",null,"Happy Testing!"),(0,a.kt)("h2",{id:"about-the-author"},"About The Author"),(0,a.kt)("p",null,"Dave Haeffner is the original writer of Elemental Selenium -- a free, once weekly Selenium tip newsletter that's\nread by thousands of testing professionals. He also created and maintains the-internet (an open-source web app\nthat's perfect for writing automated tests against)."),(0,a.kt)("p",null,"Dave has helped numerous companies successfully implement automated acceptance testing; including The Motley Fool,\nManTech International, Sittercity, and Animoto. He is also an active member of the Selenium project and has spoken\nat numerous conferences and meetups around the world about automated acceptance testing."))}f.isMDXComponent=!0}}]);